---
date: '2024-11-27'
title: "4장 분산 메시지 큐"
categories: [ 'study', "DIL" ]
summary: "대규모 시스템 설계 기초 2 4장 분산 메시지 큐 발표 자료"
thumbnail: '../../common.png'
---

메시지 큐 장점
> - 결합도 완화
> - 규모 확장성 완화
> - 가용성 개선
> - 성능 개선 (비동기 처리)

메시지 큐 단점
> - 시스템 복잡성 증가
> - 일관성 보장 어려움
> - 성능 오버헤드
> - DLQ 나 처리 실패 시나리오 처리
> - 모니터링 및 디버깅 어려움



AWS 메시지 큐, 이벤트 스트리밍 플랫폼
> SQS: 메시지 큐,
> MSK(Managed Service Kafka)
> Kinesis: 스트리밍 데이터 플랫폼

[Kinesis 와 MSK 비교](https://programmaticponderings.com/2023/04/23/streaming-data-on-aws-amazon-kinesis-data-streams-or-amazon-msk/)

이번 장에서는

- 데이터 장기 보관
- 메시지 반복 소비
  기능을 가진 분산 메시지 큐를 설계해 볼 것.

# 문제 이해 및 설계 범위 확정

### 기능 요구사항

- 생산자는 메시지 큐에 메시지 보냄
- 소비자는 메시지 큐에서 메시지 가져옴
- 메시지는 반복적으로 수신할 수도 있고 단 한 번만 수신하도록 할 수도 있어야 함
- 오래된 이력 데이터는 삭제될 수 있음.
- 메시지 크기는 킬로바이트 수준
- 메시지는 생산된 순서대로 소비자에게 전달될 수 있어야 함.
- 메시지 전달 방식
    - 최소 한 번
    - 최대 한 번
    - 정확히 한 번

### 비기능 요구사항

- 높은 대역폭과 낮은 전송 지연 가운데 하나를 설정
- 규모 확장성. 수백만 개의 메시지를 처리할 수 있어야 함.
- 지속성 및 내구성. 데이터는 디스크에 지속적으로 보관되어야 하며 여러 노드에 복제되어야 함.

### 전통적 메시지 큐와 다른점

- 데이터 장기 보관
- 메시지 전달 순서 보존 (파티션 내에서만 순서 보존)

# 개략적 설계안 제시 및 동의 구하기

## 일대일 모델

- 각 메시지는 한 소비자만 가져갈 수 있다.
- ACK 를 받은 메시지는 삭제

## 발행/구독 모델

- "토픽" 이라는 개념이 등장.

> - RabbitMQ 에서는 Topic Exchange 로 라우팅 방식을 결정  
    예를 들어 Order Server 에서 order.created 라는 토픽으로 메시지를 보내면
    Payment Server 에서는 order.created, order.* 등의 패턴으로 큐를 만들어서 메시지를 받을 수 있음.
> - Kafka 에서는 Topic 이라는 개념이 있음. Topic 은 여러 파티션으로 나뉘어져 있음.

## 토픽, 파티션, 브로커

토픽에 보관되는 양이 많아지면? -> 파티션, 즉 샤딩기법을 활용
토픽을 여러 파티션으로 나누어 모든 파티션에 균등하게 분배.

파티션을 유지하는 서버는 브로커라고 부름.

파티션을 균등하게 분배하는 것 -> 높은 규모의 확장성,

토픽의 용량을 확장하고 싶으면 파티션 개수를 늘리면 됨.

각 토픽의 파티션은 FIFO 큐 처럼 동작. -> 같은 파티션 안에서는 메시지 순서가 유지됨.

파티션 내에서 메시지 위치는 오프셋(offset) 이라 불림.

메시지는 사용자ID 같은 키를 붙일 수 있는데, 같은 키를 가진 메시지는 같은 파티션으로 보내짐.

키가 없으면 무작위 파티션을 선택.

소비자는 하나 이상의 파티션에서 데이터를 가져옴.

## 소비자 그룹

하나의 소비자 그룹은 여러 토픽을 구독할 수 있고 별도로 오프셋을 관리함.
> 다른 소비자 그룹이 존재하고 서로 다른 소비자 그룹이 같은 파티션을 소비하더라도
> 별도의 오프셋으로 관리하기 때문에 데이터를 읽는데 영향을 주지 않음.

같은 그룹 내 소비자는 메시지를 병렬로 소비가능.

여기서 문제가 발생하는 부분: 병렬로 소비하면 대역폭 측면에서는 좋지만 메시지 순서가 보장되지 않음.

제약사항: 어떤 파티션은 하나의 소비자 그룹안에서는 오직 하나의 소비자만 소비하도록 제한.
> [RabbitMQ는 순서를 보장할 수 없을까?](https://stackoverflow.com/questions/21363302/rabbitmq-message-order-of-delivery)
>
> Kafka 도 파티션내에서만 유지되기 때문에 적절한 파티셔닝을 해야 순서가 보장됨.

# 상세 설계

1. 데이터 장기 보관
2. 높은 대역폭

만족하는 다음의 결정.

- 회전 디스크의 높은 순차 탐색 성능, 적극적 디스크 캐시 전략을 사용가능한 디스크 기반 자료구조 선택
- 생산자로부터 소비자에게 전달되는 순간까지 아무 수정 없는 메시지 자료구조. (메시지 복사에 드는 비용을 최소화)
- 일괄 처리(Batching) 우선하는 시스템 설계. 소규모 I/O 작업을 줄이기 위해 메시지를 배치로 전송, 소비자도 배치로 메시지를 가져옴.

### 데이터 저장소

고려사항

- 읽기와 쓰기가 빈번함.
- 갱신 / 삭제는 이루어지지 않음.
- 순차적인 읽기/쓰기가 대부분.

1. 데이터베이스:   
   읽기 쓰기가 동시에 대규모로 빈번하게 발생. -> 데이터베이스는 부하가 커짐.

2. 쓰기 우선 로그(Write-Ahead Log, WAL)   
   새로운 항목이 추가되기만 하는 일반 파일. Mysql 의 redo log, 아파치 주키퍼가 활용중
   WAL에 대한 접근 패턴은 읽기/쓰기 전부 순차적. 디스크는 아주 좋은 성능에 가격도 저렴.

파일은 무한정 커질 수 없으니 세그먼트(segment)로 나누어 관리.
활성 세그먼트, 비활성 세그먼트가 존재하며 데이터의 추가는 활성 세그먼트에만 이루어지고
해당 활성 세그먼트의 크기가 일정 한계에 도달하면 새 활성 세그먼트를 만들어 새로운 메시지를 수용.
비활성 세그먼트는 보관 기한이 만료되거나 용량 한계에 도달하면 삭제가능.

성능 유의사항.
회전식 디스크가 느리다는 것은 접근 패턴이 무작위일때.

### 메시지 자료구조

- 메시지 키
    - 파티션을 결정하는데 사용가능.
- 메시지 값
- 토픽
- 파티션
- 오프셋
- 타임 스탬프
- 크기
- CRC (순환 중복 검사)

WAL 로 오프셋, 파티션 등등을 추가해서 저장하며 한번 저장한 뒤로는 수정 X

### 일괄처리

장점

1. I/O 작업을 줄임
2. 여러 메시지를 한 번에 로그에 기록 -> 큰 규모의 순차 쓰기 연산 -> 운영체제의 디스크 캐시에서 큰 규모의 연속된 공간점유 -> 높은 디스크 접근 대역폭

높은 대역폭과 낮은 응답 지연은 동시에 달성하기 힘듬.

## 생산자 측 작업 흐름

### 프로세스 1

가정: 생산자가 특정 파티션에 메시지를 보낸다고 가정.

문제: 어느 브로커에 메시지를 보내야 할지 결정해야 함.

해결: 라우팅 계층 도입. 라우팅 계층은 적절한 브로커를 선택하고 메시지를 전달.

이 때 적절한 브로커는 리더 브로커(Leader Broker) 라고 부름.

리더 브로커는 우선 메시지를 받고 해당 리더를 따르는 다른 브로커는 리더 브로커로부터 데이터를 받음.

'충분한' 수의 사본이 동기화되면 리더는 데이터를 디스크에 기록. 기록이 끝나면 생산자에게 회신

리더와 사본이 필요한 이유? 장애 감내(fault tolerance)를 위해.

### 프로세스 2

프로세스 1의 문제점: 라우팅 계층은 네트워크 오버헤드가 발생, 일괄처리가 불가능한 부분

해결: 라우팅 계층을 생산자에게 두어서 생산자가 직접 브로커에게 메시지를 보내도록 함.

장점: 전송 지연이 줄어듬, 어느 파티션에 보내야 하는 결정 로직을 가질 수 있음, 일괄 처리가능.

## 소비자 측 작업 흐름

소비자는 특정 파티션의 오프셋을 주고 해당 위치로부터 이벤트를 묶어 가져옴.

### 푸시 / 풀

Push

장점:

- 낮은 지연 (받는 즉시 client 에게 전달)

단점:

- 소비자가 처리할 수 없을 정도로 빠르게 메시지가 들어오면 부하 증가
- 생산자가 데이터 전송 속도를 좌우하므로 소비자는 그에 맞는 컴퓨팅 자원을 준비해야함.

Pull

장점:

- 어떤 소비자는 실시간으로 어떤 소비자는 Batch 로 처리하도록 조절 가능.

단점:

- 메시지가 없어도 계속 데이터 요구, 즉 소비자측 컴퓨팅 자원낭비 발생.

대부분 Pull 방식을 사용.

풀 모델을 지원하는 메시지 큐의 동작 흐름도.

1. 소비자 그룹에 합류하고 토픽을 구독하길 원하는 새로운 소비자가 등장.
2. 소비자는 그룹 이름을 해싱하여 브로커 노드를 찾는다. -> 같은 소비자 그룹의 모든 소비자들은 같은 브로커에 연결됨
3. 해당 브로커 노드는 소비자 그룹의 코디네이터라고 부름. 브로커 클러스터 조정 작업과 다름.
4. 코디네이터는 소비자를 그룹에 참여하고 파티션을 할당. 파티션 할당 정책에는 라운드 로빈, 범위 기반 정책 등 여러가지가 존재.
5. 소비자는 상태저장소(state storage) 로부터 오프셋 정보를 가져옴.
6. 소비자는 메시지를 처리하고 새로운 오프셋을 브로커에 보냄.

> 여기서 코디네이터는 리더 브로커와는 다름.

### 상태 저장소

- 소비자에 대한 파티션의 배치 관계 저장.
- 각 소비자 그룹이 각 파티션에서 처리한 마지막 오프셋 정보 저장.

데이터 특징.

1. 읽기 쓰기가 빈번하게 발생하지만 양은 많지 않음.
2. 데이터 갱신은 빈번하게 일어나지만 삭제되는 일은 거의 없다.
3. 읽기 쓰기가 무작위적 패턴.
4. 데이터 일관성이 중요.

Apache Zookeeper, etcd

> [동물원을-탈출한-카프카](https://psm1782.medium.com/%EB%8F%99%EB%AC%BC%EC%9B%90%EC%9D%84-%ED%83%88%EC%B6%9C%ED%95%9C-%EC%B9%B4%ED%94%84%EC%B9%B4-zookeeper-less-kafka-a71cba58d5d9)

### 메타데이터 저장소.

- 토픽 설정이나 속성 정보를 저장. (파티션 수, 메시지 보관 기간, 사본 배치 정보 등

데이터 특징.

1. 자주 변경되지 않으며 양도 적음.
2. 높은 일관성 요구

마찬가지로 Zookeeper, etcd 등을 활용.

## 복제.

하드웨어 장애에 대비하여서 파티션 내의 데이터를 복제하여 안정성을 확보.

사본을 어떻게 어떻게 분산할지 기술하는 것 -> 사본 분산 계획 (replica distribution plan)

예) 토픽 A의 파티션-1: 사본 3개 리더는 브로커-1, 단순 사본은 브로커-2, 브로커-3 배치

사본 분산 계획은 조정 서비스에 의해서 브로커 노드 가운데 하나가 선정되면 해당 리더 브로커 노드가
사본 분산 계획을 만들고 메타데이터 저장소에 보관.

### 사본 동기화

메시지 소실을 대비해서 각 파티션은 여러 사본으로 복제됨.

메시지는 리더한테만 보내고 다른 단순 사본은 리더에서 메시지를 가져와서 동기화.

동기화는 어떻게??

In-Sync Replicas (ISR) : 리더와 동기화된 사본들.

예를들어 replica.lag.max.message 의 값이 4일 경우
단순 사본에 보관된 메시지 개수와 리더 사이의 차이가 3개 이하면 ISR 상태.

- 리더 사본의 합의 오프셋(committed offset) 의미: 이 오프셋 이전에 기록된 모든 메시지는 ISR 집합 내 모든 사본에 동기화가 끝났다는 것.

> - ISR 크기가 너무 작아지면 가용성에 문제가 생길 수 있음
> - min.insync.replicas 설정값이 너무 높으면 성능이 저하될 수 있음

ISR 이 필요한 이유. 성능과 영속성 사이의 타협점.

### ACK=all

모든 ISR 사본이 메시지를 처리하고 오프셋을 보내야지만 메시지 처리가 완료됨.

### ACK=1

리더 사본만 메시지를 처리하고 오프셋을 보내면 메시지 처리가 완료됨.

데이터가 사라져도 괜찮은 경우에 사용.

### ACK=0

수신 확인 메시지를 기다리지 않음.

Metric, Log, Event 등의 데이터에 사용.


> 리더 사본에 요청이 너무 몰리면 어떻게 될까? ISR 요건을 만족하는 사본에서 메시지를 가져가지 않는 이유?
> - 설계 및 운영이 단순.
> - 특정 파티션의 메시지는 같은 소비자 그룹 안에서 오직 한 소비자만 읽어갈 수 있으므로 리더 사본에 대한 연결이 많지 않음.
> - 인기있는 토픽의 경우 파티션 및 소비자 수를 늘려 규모를 확장.

## 규모 확장성

### 생산자, 소비자

생산자 - 간단
소비자 - 소비자 그룹은 서로 독립적으로 쉽게 추가 및 삭제 가능. 재조정 코디네이터에 의해서 진행.

### 브로커

> 146p 그림 4.28 브로커 노드의 장애 참고

1. 메시지가 성공적으로 합의(committed) 되었다고 판단하려면 얼마나 많은 사본에 메시지가 반영되어야하는가? 응답 지연과 안정성 사이의 트레이드 오프 고려
2. 파티션의 모든 사본이 같은 브로커에 배치되지 않도록 주의. 브로커 장애시 모든 사본이 손실될 수 있음.

> 148p 그림 4.29 새 브로커 노드의 추가 참고

한시적으로 시스템에 설정된 사본 수 보다 많은 사본을 허용. -> 브로커 추가
한시적으로 시스템에 설정된 사본 수 보다 적은 사본을 유지. -> 브로커 삭제

### 파티션

파티션 수를 조정해야할 때 생산자는 브로커와 통신할 때 통지 받으며 소비자는 재조정을 시행함. -> 생산자와 소비자의 안정성에는 영향을 끼치지 않음.

## 메시지 전달 방식

### 최대 한번

ACK=0

### 최소 한번

ACK=1, ACK=all

### 정확히 한번

[Exactly Once Semantics](https://huisam.tistory.com/entry/kafka-message-semantics)

## 고급 기능

### 메시지 필터링

생산자는 토픽에 모든 메시지를 발행하지만 소비자가 해당 토픽의 특정한 이벤트만 가져오고 싶은 경우가 있음.

간단한 방법 -> 토픽을 분리하는 것
다음의 단점이 존재.

1. 요구사항 마다 토픽을 분리하는 것은 관리상 어려움.
2. 토픽을 분리하면서 생기는 데이터 중복 문제.
3. 생산자와 소비자 결합도 증가.

모든 메시지를 소비자에서 필요없는 메시지는 버리는 방법이 있음.

다음의 단점이 존재.

1. 불필요한 트래픽 발생 -> 네트워크 부하
2. 성능 저하

브로커 레벨에서 메시지 필터링을 지원하는 방법이 있음.

다음의 사항들을 고려해야함.

1. 필터를 위해 복호화나 역직렬화가 필요하다면 성능이 저하됨.
2. payload가 아닌 metadata 영역을 효율적으로 활용 -> tag, header 등

### 메시지 지연 전송

# 추가적으로 알아보기

- AMQP 프로토콜
- Kafka Protocol
- Retry Consumer (메시지 소비 재시도)

