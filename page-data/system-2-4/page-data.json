{"componentChunkName":"component---src-templates-post-template-tsx","path":"/system-2-4/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"html":"<p>메시지 큐 장점</p>\n<blockquote>\n<ul>\n<li>결합도 완화</li>\n<li>규모 확장성 완화</li>\n<li>가용성 개선</li>\n<li>성능 개선 (비동기 처리)</li>\n</ul>\n</blockquote>\n<p>메시지 큐 단점</p>\n<blockquote>\n<ul>\n<li>시스템 복잡성 증가</li>\n<li>일관성 보장 어려움</li>\n<li>성능 오버헤드</li>\n<li>DLQ 나 처리 실패 시나리오 처리</li>\n<li>모니터링 및 디버깅 어려움</li>\n</ul>\n</blockquote>\n<p>AWS 메시지 큐, 이벤트 스트리밍 플랫폼</p>\n<blockquote>\n<p>SQS: 메시지 큐,\nMSK(Managed Service Kafka)\nKinesis: 스트리밍 데이터 플랫폼</p>\n</blockquote>\n<p><a href=\"https://programmaticponderings.com/2023/04/23/streaming-data-on-aws-amazon-kinesis-data-streams-or-amazon-msk/\" target=\"_blank\" rel=\"nofollow\">Kinesis 와 MSK 비교</a></p>\n<p>이번 장에서는</p>\n<ul>\n<li>데이터 장기 보관</li>\n<li>메시지 반복 소비\n기능을 가진 분산 메시지 큐를 설계해 볼 것.</li>\n</ul>\n<h1>문제 이해 및 설계 범위 확정</h1>\n<h3>기능 요구사항</h3>\n<ul>\n<li>생산자는 메시지 큐에 메시지 보냄</li>\n<li>소비자는 메시지 큐에서 메시지 가져옴</li>\n<li>메시지는 반복적으로 수신할 수도 있고 단 한 번만 수신하도록 할 수도 있어야 함</li>\n<li>오래된 이력 데이터는 삭제될 수 있음.</li>\n<li>메시지 크기는 킬로바이트 수준</li>\n<li>메시지는 생산된 순서대로 소비자에게 전달될 수 있어야 함.</li>\n<li>메시지 전달 방식\n<ul>\n<li>최소 한 번</li>\n<li>최대 한 번</li>\n<li>정확히 한 번</li>\n</ul>\n</li>\n</ul>\n<h3>비기능 요구사항</h3>\n<ul>\n<li>높은 대역폭과 낮은 전송 지연 가운데 하나를 설정</li>\n<li>규모 확장성. 수백만 개의 메시지를 처리할 수 있어야 함.</li>\n<li>지속성 및 내구성. 데이터는 디스크에 지속적으로 보관되어야 하며 여러 노드에 복제되어야 함.</li>\n</ul>\n<h3>전통적 메시지 큐와 다른점</h3>\n<ul>\n<li>데이터 장기 보관</li>\n<li>메시지 전달 순서 보존 (파티션 내에서만 순서 보존)</li>\n</ul>\n<h1>개략적 설계안 제시 및 동의 구하기</h1>\n<h2>일대일 모델</h2>\n<ul>\n<li>각 메시지는 한 소비자만 가져갈 수 있다.</li>\n<li>ACK 를 받은 메시지는 삭제</li>\n</ul>\n<h2>발행/구독 모델</h2>\n<ul>\n<li>“토픽” 이라는 개념이 등장.</li>\n</ul>\n<blockquote>\n<ul>\n<li>RabbitMQ 에서는 Topic Exchange 로 라우팅 방식을 결정</li>\n</ul>\n</blockquote>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">예를 들어 Order Server 에서 order.created 라는 토픽으로 메시지를 보내면\nPayment Server 에서는 order.created, order.* 등의 패턴으로 큐를 만들어서 메시지를 받을 수 있음.</code></pre></div>\n<blockquote>\n<ul>\n<li>Kafka 에서는 Topic 이라는 개념이 있음. Topic 은 여러 파티션으로 나뉘어져 있음.</li>\n</ul>\n</blockquote>\n<h2>토픽, 파티션, 브로커</h2>\n<p>토픽에 보관되는 양이 많아지면? -> 파티션, 즉 샤딩기법을 활용\n토픽을 여러 파티션으로 나누어 모든 파티션에 균등하게 분배.</p>\n<p>파티션을 유지하는 서버는 브로커라고 부름.</p>\n<p>파티션을 균등하게 분배하는 것 -> 높은 규모의 확장성,</p>\n<p>토픽의 용량을 확장하고 싶으면 파티션 개수를 늘리면 됨.</p>\n<p>각 토픽의 파티션은 FIFO 큐 처럼 동작. -> 같은 파티션 안에서는 메시지 순서가 유지됨.</p>\n<p>파티션 내에서 메시지 위치는 오프셋(offset) 이라 불림.</p>\n<p>메시지는 사용자ID 같은 키를 붙일 수 있는데, 같은 키를 가진 메시지는 같은 파티션으로 보내짐.</p>\n<p>키가 없으면 무작위 파티션을 선택.</p>\n<p>소비자는 하나 이상의 파티션에서 데이터를 가져옴.</p>\n<h2>소비자 그룹</h2>\n<p>하나의 소비자 그룹은 여러 토픽을 구독할 수 있고 별도로 오프셋을 관리함.</p>\n<blockquote>\n<p>다른 소비자 그룹이 존재하고 서로 다른 소비자 그룹이 같은 파티션을 소비하더라도\n별도의 오프셋으로 관리하기 때문에 데이터를 읽는데 영향을 주지 않음.</p>\n</blockquote>\n<p>같은 그룹 내 소비자는 메시지를 병렬로 소비가능.</p>\n<p>여기서 문제가 발생하는 부분: 병렬로 소비하면 대역폭 측면에서는 좋지만 메시지 순서가 보장되지 않음.</p>\n<p>제약사항: 어떤 파티션은 하나의 소비자 그룹안에서는 오직 하나의 소비자만 소비하도록 제한.</p>\n<blockquote>\n<p><a href=\"https://stackoverflow.com/questions/21363302/rabbitmq-message-order-of-delivery\" target=\"_blank\" rel=\"nofollow\">RabbitMQ는 순서를 보장할 수 없을까?</a></p>\n<p>Kafka 도 파티션내에서만 유지되기 때문에 적절한 파티셔닝을 해야 순서가 보장됨.</p>\n</blockquote>\n<h1>상세 설계</h1>\n<ol>\n<li>데이터 장기 보관</li>\n<li>높은 대역폭</li>\n</ol>\n<p>만족하는 다음의 결정.</p>\n<ul>\n<li>회전 디스크의 높은 순차 탐색 성능, 적극적 디스크 캐시 전략을 사용가능한 디스크 기반 자료구조 선택</li>\n<li>생산자로부터 소비자에게 전달되는 순간까지 아무 수정 없는 메시지 자료구조. (메시지 복사에 드는 비용을 최소화)</li>\n<li>일괄 처리(Batching) 우선하는 시스템 설계. 소규모 I/O 작업을 줄이기 위해 메시지를 배치로 전송, 소비자도 배치로 메시지를 가져옴.</li>\n</ul>\n<h3>데이터 저장소</h3>\n<p>고려사항</p>\n<ul>\n<li>읽기와 쓰기가 빈번함.</li>\n<li>갱신 / 삭제는 이루어지지 않음.</li>\n<li>순차적인 읽기/쓰기가 대부분.</li>\n</ul>\n<ol>\n<li>\n<p>데이터베이스:<br>\n읽기 쓰기가 동시에 대규모로 빈번하게 발생. -> 데이터베이스는 부하가 커짐.</p>\n</li>\n<li>\n<p>쓰기 우선 로그(Write-Ahead Log, WAL)<br>\n새로운 항목이 추가되기만 하는 일반 파일. Mysql 의 redo log, 아파치 주키퍼가 활용중\nWAL에 대한 접근 패턴은 읽기/쓰기 전부 순차적. 디스크는 아주 좋은 성능에 가격도 저렴.</p>\n</li>\n</ol>\n<p>파일은 무한정 커질 수 없으니 세그먼트(segment)로 나누어 관리.\n활성 세그먼트, 비활성 세그먼트가 존재하며 데이터의 추가는 활성 세그먼트에만 이루어지고\n해당 활성 세그먼트의 크기가 일정 한계에 도달하면 새 활성 세그먼트를 만들어 새로운 메시지를 수용.\n비활성 세그먼트는 보관 기한이 만료되거나 용량 한계에 도달하면 삭제가능.</p>\n<p>성능 유의사항.\n회전식 디스크가 느리다는 것은 접근 패턴이 무작위일때.</p>\n<h3>메시지 자료구조</h3>\n<ul>\n<li>메시지 키\n<ul>\n<li>파티션을 결정하는데 사용가능.</li>\n</ul>\n</li>\n<li>메시지 값</li>\n<li>토픽</li>\n<li>파티션</li>\n<li>오프셋</li>\n<li>타임 스탬프</li>\n<li>크기</li>\n<li>CRC (순환 중복 검사)</li>\n</ul>\n<p>WAL 로 오프셋, 파티션 등등을 추가해서 저장하며 한번 저장한 뒤로는 수정 X</p>\n<h3>일괄처리</h3>\n<p>장점</p>\n<ol>\n<li>I/O 작업을 줄임</li>\n<li>여러 메시지를 한 번에 로그에 기록 -> 큰 규모의 순차 쓰기 연산 -> 운영체제의 디스크 캐시에서 큰 규모의 연속된 공간점유 -> 높은 디스크 접근 대역폭</li>\n</ol>\n<p>높은 대역폭과 낮은 응답 지연은 동시에 달성하기 힘듬.</p>\n<h2>생산자 측 작업 흐름</h2>\n<h3>프로세스 1</h3>\n<p>가정: 생산자가 특정 파티션에 메시지를 보낸다고 가정.</p>\n<p>문제: 어느 브로커에 메시지를 보내야 할지 결정해야 함.</p>\n<p>해결: 라우팅 계층 도입. 라우팅 계층은 적절한 브로커를 선택하고 메시지를 전달.</p>\n<p>이 때 적절한 브로커는 리더 브로커(Leader Broker) 라고 부름.</p>\n<p>리더 브로커는 우선 메시지를 받고 해당 리더를 따르는 다른 브로커는 리더 브로커로부터 데이터를 받음.</p>\n<p>‘충분한’ 수의 사본이 동기화되면 리더는 데이터를 디스크에 기록. 기록이 끝나면 생산자에게 회신</p>\n<p>리더와 사본이 필요한 이유? 장애 감내(fault tolerance)를 위해.</p>\n<h3>프로세스 2</h3>\n<p>프로세스 1의 문제점: 라우팅 계층은 네트워크 오버헤드가 발생, 일괄처리가 불가능한 부분</p>\n<p>해결: 라우팅 계층을 생산자에게 두어서 생산자가 직접 브로커에게 메시지를 보내도록 함.</p>\n<p>장점: 전송 지연이 줄어듬, 어느 파티션에 보내야 하는 결정 로직을 가질 수 있음, 일괄 처리가능.</p>\n<h2>소비자 측 작업 흐름</h2>\n<p>소비자는 특정 파티션의 오프셋을 주고 해당 위치로부터 이벤트를 묶어 가져옴.</p>\n<h3>푸시 / 풀</h3>\n<p>Push</p>\n<p>장점:</p>\n<ul>\n<li>낮은 지연 (받는 즉시 client 에게 전달)</li>\n</ul>\n<p>단점:</p>\n<ul>\n<li>소비자가 처리할 수 없을 정도로 빠르게 메시지가 들어오면 부하 증가</li>\n<li>생산자가 데이터 전송 속도를 좌우하므로 소비자는 그에 맞는 컴퓨팅 자원을 준비해야함.</li>\n</ul>\n<p>Pull</p>\n<p>장점:</p>\n<ul>\n<li>어떤 소비자는 실시간으로 어떤 소비자는 Batch 로 처리하도록 조절 가능.</li>\n</ul>\n<p>단점:</p>\n<ul>\n<li>메시지가 없어도 계속 데이터 요구, 즉 소비자측 컴퓨팅 자원낭비 발생.</li>\n</ul>\n<p>대부분 Pull 방식을 사용.</p>\n<p>풀 모델을 지원하는 메시지 큐의 동작 흐름도.</p>\n<ol>\n<li>소비자 그룹에 합류하고 토픽을 구독하길 원하는 새로운 소비자가 등장.</li>\n<li>소비자는 그룹 이름을 해싱하여 브로커 노드를 찾는다. -> 같은 소비자 그룹의 모든 소비자들은 같은 브로커에 연결됨</li>\n<li>해당 브로커 노드는 소비자 그룹의 코디네이터라고 부름. 브로커 클러스터 조정 작업과 다름.</li>\n<li>코디네이터는 소비자를 그룹에 참여하고 파티션을 할당. 파티션 할당 정책에는 라운드 로빈, 범위 기반 정책 등 여러가지가 존재.</li>\n<li>소비자는 상태저장소(state storage) 로부터 오프셋 정보를 가져옴.</li>\n<li>소비자는 메시지를 처리하고 새로운 오프셋을 브로커에 보냄.</li>\n</ol>\n<blockquote>\n<p>여기서 코디네이터는 리더 브로커와는 다름.</p>\n</blockquote>\n<h3>상태 저장소</h3>\n<ul>\n<li>소비자에 대한 파티션의 배치 관계 저장.</li>\n<li>각 소비자 그룹이 각 파티션에서 처리한 마지막 오프셋 정보 저장.</li>\n</ul>\n<p>데이터 특징.</p>\n<ol>\n<li>읽기 쓰기가 빈번하게 발생하지만 양은 많지 않음.</li>\n<li>데이터 갱신은 빈번하게 일어나지만 삭제되는 일은 거의 없다.</li>\n<li>읽기 쓰기가 무작위적 패턴.</li>\n<li>데이터 일관성이 중요.</li>\n</ol>\n<p>Apache Zookeeper, etcd</p>\n<blockquote>\n<p><a href=\"https://psm1782.medium.com/%EB%8F%99%EB%AC%BC%EC%9B%90%EC%9D%84-%ED%83%88%EC%B6%9C%ED%95%9C-%EC%B9%B4%ED%94%84%EC%B9%B4-zookeeper-less-kafka-a71cba58d5d9\" target=\"_blank\" rel=\"nofollow\">동물원을-탈출한-카프카</a></p>\n</blockquote>\n<h3>메타데이터 저장소.</h3>\n<ul>\n<li>토픽 설정이나 속성 정보를 저장. (파티션 수, 메시지 보관 기간, 사본 배치 정보 등</li>\n</ul>\n<p>데이터 특징.</p>\n<ol>\n<li>자주 변경되지 않으며 양도 적음.</li>\n<li>높은 일관성 요구</li>\n</ol>\n<p>마찬가지로 Zookeeper, etcd 등을 활용.</p>\n<h2>복제.</h2>\n<p>하드웨어 장애에 대비하여서 파티션 내의 데이터를 복제하여 안정성을 확보.</p>\n<p>사본을 어떻게 어떻게 분산할지 기술하는 것 -> 사본 분산 계획 (replica distribution plan)</p>\n<p>예) 토픽 A의 파티션-1: 사본 3개 리더는 브로커-1, 단순 사본은 브로커-2, 브로커-3 배치</p>\n<p>사본 분산 계획은 조정 서비스에 의해서 브로커 노드 가운데 하나가 선정되면 해당 리더 브로커 노드가\n사본 분산 계획을 만들고 메타데이터 저장소에 보관.</p>\n<h3>사본 동기화</h3>\n<p>메시지 소실을 대비해서 각 파티션은 여러 사본으로 복제됨.</p>\n<p>메시지는 리더한테만 보내고 다른 단순 사본은 리더에서 메시지를 가져와서 동기화.</p>\n<p>동기화는 어떻게??</p>\n<p>In-Sync Replicas (ISR) : 리더와 동기화된 사본들.</p>\n<p>예를들어 replica.lag.max.message 의 값이 4일 경우\n단순 사본에 보관된 메시지 개수와 리더 사이의 차이가 3개 이하면 ISR 상태.</p>\n<ul>\n<li>리더 사본의 합의 오프셋(committed offset) 의미: 이 오프셋 이전에 기록된 모든 메시지는 ISR 집합 내 모든 사본에 동기화가 끝났다는 것.</li>\n</ul>\n<blockquote>\n<ul>\n<li>ISR 크기가 너무 작아지면 가용성에 문제가 생길 수 있음</li>\n<li>min.insync.replicas 설정값이 너무 높으면 성능이 저하될 수 있음</li>\n</ul>\n</blockquote>\n<p>ISR 이 필요한 이유. 성능과 영속성 사이의 타협점.</p>\n<h3>ACK=all</h3>\n<p>모든 ISR 사본이 메시지를 처리하고 오프셋을 보내야지만 메시지 처리가 완료됨.</p>\n<h3>ACK=1</h3>\n<p>리더 사본만 메시지를 처리하고 오프셋을 보내면 메시지 처리가 완료됨.</p>\n<p>데이터가 사라져도 괜찮은 경우에 사용.</p>\n<h3>ACK=0</h3>\n<p>수신 확인 메시지를 기다리지 않음.</p>\n<p>Metric, Log, Event 등의 데이터에 사용.</p>\n<blockquote>\n<p>리더 사본에 요청이 너무 몰리면 어떻게 될까? ISR 요건을 만족하는 사본에서 메시지를 가져가지 않는 이유?</p>\n<ul>\n<li>설계 및 운영이 단순.</li>\n<li>특정 파티션의 메시지는 같은 소비자 그룹 안에서 오직 한 소비자만 읽어갈 수 있으므로 리더 사본에 대한 연결이 많지 않음.</li>\n<li>인기있는 토픽의 경우 파티션 및 소비자 수를 늘려 규모를 확장.</li>\n</ul>\n</blockquote>\n<h2>규모 확장성</h2>\n<h3>생산자, 소비자</h3>\n<p>생산자 - 간단\n소비자 - 소비자 그룹은 서로 독립적으로 쉽게 추가 및 삭제 가능. 재조정 코디네이터에 의해서 진행.</p>\n<h3>브로커</h3>\n<blockquote>\n<p>146p 그림 4.28 브로커 노드의 장애 참고</p>\n</blockquote>\n<ol>\n<li>메시지가 성공적으로 합의(committed) 되었다고 판단하려면 얼마나 많은 사본에 메시지가 반영되어야하는가? 응답 지연과 안정성 사이의 트레이드 오프 고려</li>\n<li>파티션의 모든 사본이 같은 브로커에 배치되지 않도록 주의. 브로커 장애시 모든 사본이 손실될 수 있음.</li>\n</ol>\n<blockquote>\n<p>148p 그림 4.29 새 브로커 노드의 추가 참고</p>\n</blockquote>\n<p>한시적으로 시스템에 설정된 사본 수 보다 많은 사본을 허용. -> 브로커 추가\n한시적으로 시스템에 설정된 사본 수 보다 적은 사본을 유지. -> 브로커 삭제</p>\n<h3>파티션</h3>\n<p>파티션 수를 조정해야할 때 생산자는 브로커와 통신할 때 통지 받으며 소비자는 재조정을 시행함. -> 생산자와 소비자의 안정성에는 영향을 끼치지 않음.</p>\n<h2>메시지 전달 방식</h2>\n<h3>최대 한번</h3>\n<p>ACK=0</p>\n<h3>최소 한번</h3>\n<p>ACK=1, ACK=all</p>\n<h3>정확히 한번</h3>\n<p><a href=\"https://huisam.tistory.com/entry/kafka-message-semantics\" target=\"_blank\" rel=\"nofollow\">Exactly Once Semantics</a></p>\n<h2>고급 기능</h2>\n<h3>메시지 필터링</h3>\n<p>생산자는 토픽에 모든 메시지를 발행하지만 소비자가 해당 토픽의 특정한 이벤트만 가져오고 싶은 경우가 있음.</p>\n<p>간단한 방법 -> 토픽을 분리하는 것\n다음의 단점이 존재.</p>\n<ol>\n<li>요구사항 마다 토픽을 분리하는 것은 관리상 어려움.</li>\n<li>토픽을 분리하면서 생기는 데이터 중복 문제.</li>\n<li>생산자와 소비자 결합도 증가.</li>\n</ol>\n<p>모든 메시지를 소비자에서 필요없는 메시지는 버리는 방법이 있음.</p>\n<p>다음의 단점이 존재.</p>\n<ol>\n<li>불필요한 트래픽 발생 -> 네트워크 부하</li>\n<li>성능 저하</li>\n</ol>\n<p>브로커 레벨에서 메시지 필터링을 지원하는 방법이 있음.</p>\n<p>다음의 사항들을 고려해야함.</p>\n<ol>\n<li>필터를 위해 복호화나 역직렬화가 필요하다면 성능이 저하됨.</li>\n<li>payload가 아닌 metadata 영역을 효율적으로 활용 -> tag, header 등</li>\n</ol>\n<h3>메시지 지연 전송</h3>\n<h1>추가적으로 알아보기</h1>\n<ul>\n<li>AMQP 프로토콜</li>\n<li>Kafka Protocol</li>\n<li>Retry Consumer (메시지 소비 재시도)</li>\n</ul>","frontmatter":{"title":"4장 분산 메시지 큐","summary":"대규모 시스템 설계 기초 2 4장 분산 메시지 큐 발표 자료","date":"2024.11.27.","categories":["study","DIL"],"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAABjElEQVR42u2U207CQBCG+8g+go9hYvTCExeoGAWDB2JQsIDFghwUiJwKrXLoAkVUvPidWUAw8cIE4pUXf3e7s/v905lmlZ5dwyKl/AMXC3REfXFAhomWgX5nPqjSIchwYCEQTGBp2YtS8REv3Qm0Do5326zaeBypJ+j9RyAFPwioJ+/hP9cl8K1vwm5U5YHhi4W3nol3h0bHJFl4pZGNBrTuiJrUt082KkX4Azo8xzcIhu9kBmo0De9pHFEtg0TyAXriHvHbrDSOxTO4UlNIp3MQTQNtNm+Pgc2nKjTamM8XcKNlkcsVpI78GtZdIRyQyfZeBKtbIbgPY9h0q3DtRxCOpOAjQzU2Mj670FEghsKHr65TaBGYg+x4QtnG9ax05lpxWdidY9y4SUY8t2mNy1MpF9GwKlCezQplEsbaTghbuypWNi7h8Wl4pfpMOu5Qc7hOfVGXf8PXupiKG8kxhR/sxkUWY/Hmrj3t4uz8V//hrNNsx/4vhz8CitE9MNKcQIY0n8owjBLsliX1CTPZynf2Ss39AAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/a229594a2de7c0ed63d877869e75fd38/d0859/common.png","srcSet":"/static/a229594a2de7c0ed63d877869e75fd38/f1689/common.png 270w,\n/static/a229594a2de7c0ed63d877869e75fd38/42fd3/common.png 540w,\n/static/a229594a2de7c0ed63d877869e75fd38/d0859/common.png 1080w","sizes":"(min-width: 1080px) 1080px, 100vw"},"sources":[{"srcSet":"/static/a229594a2de7c0ed63d877869e75fd38/7e223/common.webp 270w,\n/static/a229594a2de7c0ed63d877869e75fd38/5cfb6/common.webp 540w,\n/static/a229594a2de7c0ed63d877869e75fd38/941f9/common.webp 1080w","type":"image/webp","sizes":"(min-width: 1080px) 1080px, 100vw"}]},"width":1080,"height":1080}},"publicURL":"/static/a229594a2de7c0ed63d877869e75fd38/common.png"}}}}]}},"pageContext":{"slug":"/system-2-4/"}},"staticQueryHashes":[],"slicesMap":{}}